{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "songs=pd.read_csv('data/tracks.csv')\n",
    "songs=songs.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_for_linear_regression = songs.copy()\n",
    "songs_for_linear_regression.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(dataframe,to_be_deleted):\n",
    "    dataframe.drop(to_be_deleted, axis=1, inplace=True)\n",
    "to_be_deleted = ['id_artists', 'artists','name','release_date'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_for_linear_regression['release_date'] = pd.to_datetime(songs_for_linear_regression['release_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_for_linear_regression['year'] = pd.DatetimeIndex(songs_for_linear_regression['release_date']).year\n",
    "songs_for_linear_regression['month'] = pd.DatetimeIndex(songs_for_linear_regression['release_date']).month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def scaler(dataframe,to_be_scaled):\n",
    "    scaler = sklearn.preprocessing.StandardScaler(copy = True)\n",
    "    dataframe[to_be_scaled] = scaler.fit_transform(dataframe[to_be_scaled].to_numpy())\n",
    "# to_be_scaled = ['popularity','danceability','energy','key','loudness','speechiness','acousticness','instrumentalness','liveness','valence','tempo','time_signature']\n",
    "to_be_scaled = ['loudness','duration_ms','tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns(songs_for_linear_regression,to_be_deleted)#delete columns\n",
    "songs_for_linear_regression[\"key\"] = songs_for_linear_regression[\"key\"].astype(\"category\")\n",
    "songs_for_linear_regression = pd.get_dummies(songs_for_linear_regression, columns=[\"key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs_for_linear_regression[\"year\"] = songs_for_linear_regression[\"year\"].astype(\"category\")\n",
    "# songs_for_linear_regression = pd.get_dummies(songs_for_linear_regression, columns=[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs_for_linear_regression[\"month\"] = songs_for_linear_regression[\"month\"].astype(\"category\")\n",
    "# songs_for_linear_regression = pd.get_dummies(songs_for_linear_regression, columns=[\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_for_linear_regression[(np.abs(stats.zscore(songs_for_linear_regression)) < 5).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler(songs_for_linear_regression,to_be_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_for_linear_regression.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = songs_for_linear_regression['valence']\n",
    "del songs_for_linear_regression[\"valence\"]\n",
    "songs_for_linear_regression['valence'] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND SO IT BEGINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent_variables = songs_for_linear_regression.columns.drop('valence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = songs_for_linear_regression['valence']\n",
    "# X = songs_for_linear_regression[independent_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sm.add_constant(X)\n",
    "# model11 = sm.OLS(y, X).fit()\n",
    "# model11.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR FORWARD SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHODS OF LOURIDAS FOR FORWARD SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subset(y, data, feature_set):\n",
    "    X = data.loc[:, feature_set].values\n",
    "    X = sm.add_constant(X)\n",
    "    names = ['intercept']\n",
    "    names.extend(feature_set)\n",
    "    model = sm.OLS(y, X)\n",
    "    model.data.xnames = names\n",
    "    regr = model.fit()\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_best_of_k(y, data, k):\n",
    "    \n",
    "    best_rsquared = 0\n",
    "    best_model = None\n",
    "    for comb in itertools.combinations(data.columns, k):\n",
    "        regr = process_subset(y, data, comb)\n",
    "        if regr.rsquared > best_rsquared:\n",
    "            best_rsquared = regr.rsquared\n",
    "            best_model = regr\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_subset_selection(data, exog):\n",
    "    best_model = None\n",
    "    best_models = []\n",
    "    y = data.loc[:, exog]\n",
    "    endog = [ x for x in data.columns if x != exog ]\n",
    "    X = data.loc[:, endog]\n",
    "\n",
    "    for i in range(1, len(data.columns)):\n",
    "        print(f'Finding the best model for {i} variable{\"s\" if i > 1 else \"\"}')\n",
    "        model = get_best_of_k(y, X, i)\n",
    "        if not best_model or model.rsquared_adj > best_model.rsquared_adj:\n",
    "            best_model = model\n",
    "        print(model.model.data.xnames[1:]) # get the variables minums the intercept\n",
    "        best_models.append(model)\n",
    "\n",
    "    print(f'Fitted {2**len(data.columns)} models')\n",
    "    return best_model, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_add_variable(data, exog, selected, to_select):\n",
    "    best_rsquared = 0\n",
    "    best_model = None\n",
    "    best_column = None\n",
    "    y = data.loc[:, exog]\n",
    "    \n",
    "    for column in to_select:\n",
    "        new_selected = selected + [column]\n",
    "        regr = process_subset(y, data, new_selected)\n",
    "        if regr.rsquared > best_rsquared:\n",
    "            best_rsquared = regr.rsquared\n",
    "            best_model = regr\n",
    "            best_column = column\n",
    "    \n",
    "    return best_model, best_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_selection(data, exog):\n",
    "\n",
    "    best_models = []\n",
    "    best_model = None\n",
    "    selected = []\n",
    "    to_select = [ x for x in data.columns if x != exog ]\n",
    "\n",
    "    p = len(to_select) + 1\n",
    "\n",
    "    for i in range(1, p):\n",
    "        print(f'Finding the best model for {i} variable{\"s\" if i > 1 else \"\"}')\n",
    "        model, best_column = forward_add_variable(data, exog, selected, to_select)\n",
    "        selected.append(best_column)\n",
    "        to_select.remove(best_column)\n",
    "        if not best_model or model.rsquared_adj > best_model.rsquared_adj:\n",
    "            best_model = model\n",
    "        print(selected)\n",
    "        best_models.append(model)\n",
    "        print(model.rsquared_adj)\n",
    "        \n",
    "    print(f'Fitted {1 + p*(p+1)//2} models')\n",
    "    return best_model, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the best model for 1 variable\n",
      "['danceability']\n",
      "0.3124838182838984\n",
      "Finding the best model for 2 variables\n",
      "['danceability', 'energy']\n",
      "0.365970471384645\n",
      "Finding the best model for 3 variables\n",
      "['danceability', 'energy', 'year']\n",
      "0.4509446454436268\n",
      "Finding the best model for 4 variables\n",
      "['danceability', 'energy', 'year', 'tempo']\n",
      "0.4648999590185098\n",
      "Finding the best model for 5 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms']\n",
      "0.47691383577569546\n",
      "Finding the best model for 6 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness']\n",
      "0.48856290574579175\n",
      "Finding the best model for 7 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness']\n",
      "0.4951361512433875\n",
      "Finding the best model for 8 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit']\n",
      "0.5004235989657495\n",
      "Finding the best model for 9 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness']\n",
      "0.5029244695742564\n",
      "Finding the best model for 10 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness']\n",
      "0.5050550815257875\n",
      "Finding the best model for 11 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode']\n",
      "0.5060233951874878\n",
      "Finding the best model for 12 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity']\n",
      "0.5062371336020002\n",
      "Finding the best model for 13 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9']\n",
      "0.506386441971007\n",
      "Finding the best model for 14 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5']\n",
      "0.5065295933171214\n",
      "Finding the best model for 15 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7']\n",
      "0.5066190599536022\n",
      "Finding the best model for 16 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2']\n",
      "0.5067033209400642\n",
      "Finding the best model for 17 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness']\n",
      "0.5067491288876291\n",
      "Finding the best model for 18 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1']\n",
      "0.5067914351093753\n",
      "Finding the best model for 19 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6']\n",
      "0.5068335445281327\n",
      "Finding the best model for 20 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8']\n",
      "0.5068733870065123\n",
      "Finding the best model for 21 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature']\n",
      "0.506880604201534\n",
      "Finding the best model for 22 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature', 'key_3']\n",
      "0.506885581989114\n",
      "Finding the best model for 23 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature', 'key_3', 'key_11']\n",
      "0.5068874195975311\n",
      "Finding the best model for 24 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature', 'key_3', 'key_11', 'key_4']\n",
      "0.5068858970976255\n",
      "Finding the best model for 25 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature', 'key_3', 'key_11', 'key_4', 'key_10']\n",
      "0.5068815784884055\n",
      "Finding the best model for 26 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature', 'key_3', 'key_11', 'key_4', 'key_10', 'month']\n",
      "0.5068768742447758\n",
      "Finding the best model for 27 variables\n",
      "['danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature', 'key_3', 'key_11', 'key_4', 'key_10', 'month', 'key_0']\n",
      "0.5068768742447757\n",
      "Fitted 407 models\n",
      "Best overall model: 24 ['intercept', 'danceability', 'energy', 'year', 'tempo', 'duration_ms', 'speechiness', 'acousticness', 'explicit', 'instrumentalness', 'loudness', 'mode', 'popularity', 'key_9', 'key_5', 'key_7', 'key_2', 'liveness', 'key_1', 'key_6', 'key_8', 'time_signature', 'key_3', 'key_11']\n"
     ]
    }
   ],
   "source": [
    "best_model, _ = forward_stepwise_selection(songs_for_linear_regression, 'valence')\n",
    "print('Best overall model:', len(best_model.model.exog_names), best_model.model.exog_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>valence</td>     <th>  R-squared:         </th>  <td>   0.507</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.507</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   4470.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 11 Feb 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:43:42</td>     <th>  Log-Likelihood:    </th>  <td>  27711.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>100000</td>      <th>  AIC:               </th> <td>-5.537e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 99976</td>      <th>  BIC:               </th> <td>-5.514e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>        <td>    5.6391</td> <td>    0.063</td> <td>   88.891</td> <td> 0.000</td> <td>    5.515</td> <td>    5.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>danceability</th>     <td>    0.8397</td> <td>    0.004</td> <td>  217.245</td> <td> 0.000</td> <td>    0.832</td> <td>    0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>energy</th>           <td>    0.5404</td> <td>    0.005</td> <td>  114.470</td> <td> 0.000</td> <td>    0.531</td> <td>    0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>             <td>   -0.0030</td> <td> 3.19e-05</td> <td>  -93.156</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo</th>            <td>    0.0311</td> <td>    0.001</td> <td>   51.406</td> <td> 0.000</td> <td>    0.030</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration_ms</th>      <td>   -0.0271</td> <td>    0.001</td> <td>  -45.653</td> <td> 0.000</td> <td>   -0.028</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>speechiness</th>      <td>   -0.1515</td> <td>    0.004</td> <td>  -39.777</td> <td> 0.000</td> <td>   -0.159</td> <td>   -0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acousticness</th>     <td>    0.1163</td> <td>    0.003</td> <td>   41.203</td> <td> 0.000</td> <td>    0.111</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>explicit</th>         <td>   -0.0965</td> <td>    0.003</td> <td>  -30.413</td> <td> 0.000</td> <td>   -0.103</td> <td>   -0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instrumentalness</th> <td>   -0.0495</td> <td>    0.002</td> <td>  -24.123</td> <td> 0.000</td> <td>   -0.054</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness</th>         <td>   -0.0216</td> <td>    0.001</td> <td>  -20.972</td> <td> 0.000</td> <td>   -0.024</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mode</th>             <td>    0.0181</td> <td>    0.001</td> <td>   14.026</td> <td> 0.000</td> <td>    0.016</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>       <td>    0.0002</td> <td> 3.24e-05</td> <td>    6.743</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_9</th>            <td>    0.0106</td> <td>    0.002</td> <td>    4.970</td> <td> 0.000</td> <td>    0.006</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_5</th>            <td>    0.0093</td> <td>    0.002</td> <td>    4.318</td> <td> 0.000</td> <td>    0.005</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_7</th>            <td>    0.0053</td> <td>    0.002</td> <td>    2.631</td> <td> 0.009</td> <td>    0.001</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_2</th>            <td>    0.0043</td> <td>    0.002</td> <td>    2.065</td> <td> 0.039</td> <td>    0.000</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>liveness</th>         <td>    0.0104</td> <td>    0.003</td> <td>    3.016</td> <td> 0.003</td> <td>    0.004</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_1</th>            <td>   -0.0101</td> <td>    0.002</td> <td>   -4.219</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_6</th>            <td>   -0.0105</td> <td>    0.003</td> <td>   -3.737</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_8</th>            <td>   -0.0086</td> <td>    0.003</td> <td>   -3.341</td> <td> 0.001</td> <td>   -0.014</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_signature</th>   <td>    0.0018</td> <td>    0.001</td> <td>    1.572</td> <td> 0.116</td> <td>   -0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_3</th>            <td>   -0.0046</td> <td>    0.003</td> <td>   -1.574</td> <td> 0.115</td> <td>   -0.010</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key_11</th>           <td>   -0.0031</td> <td>    0.003</td> <td>   -1.172</td> <td> 0.241</td> <td>   -0.008</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>288.260</td> <th>  Durbin-Watson:     </th> <td>   1.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 290.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.130</td>  <th>  Prob(JB):          </th> <td>6.65e-64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.048</td>  <th>  Cond. No.          </th> <td>2.16e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.16e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                valence   R-squared:                       0.507\n",
       "Model:                            OLS   Adj. R-squared:                  0.507\n",
       "Method:                 Least Squares   F-statistic:                     4470.\n",
       "Date:                Fri, 11 Feb 2022   Prob (F-statistic):               0.00\n",
       "Time:                        00:43:42   Log-Likelihood:                 27711.\n",
       "No. Observations:              100000   AIC:                        -5.537e+04\n",
       "Df Residuals:                   99976   BIC:                        -5.514e+04\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "intercept            5.6391      0.063     88.891      0.000       5.515       5.763\n",
       "danceability         0.8397      0.004    217.245      0.000       0.832       0.847\n",
       "energy               0.5404      0.005    114.470      0.000       0.531       0.550\n",
       "year                -0.0030   3.19e-05    -93.156      0.000      -0.003      -0.003\n",
       "tempo                0.0311      0.001     51.406      0.000       0.030       0.032\n",
       "duration_ms         -0.0271      0.001    -45.653      0.000      -0.028      -0.026\n",
       "speechiness         -0.1515      0.004    -39.777      0.000      -0.159      -0.144\n",
       "acousticness         0.1163      0.003     41.203      0.000       0.111       0.122\n",
       "explicit            -0.0965      0.003    -30.413      0.000      -0.103      -0.090\n",
       "instrumentalness    -0.0495      0.002    -24.123      0.000      -0.054      -0.045\n",
       "loudness            -0.0216      0.001    -20.972      0.000      -0.024      -0.020\n",
       "mode                 0.0181      0.001     14.026      0.000       0.016       0.021\n",
       "popularity           0.0002   3.24e-05      6.743      0.000       0.000       0.000\n",
       "key_9                0.0106      0.002      4.970      0.000       0.006       0.015\n",
       "key_5                0.0093      0.002      4.318      0.000       0.005       0.014\n",
       "key_7                0.0053      0.002      2.631      0.009       0.001       0.009\n",
       "key_2                0.0043      0.002      2.065      0.039       0.000       0.008\n",
       "liveness             0.0104      0.003      3.016      0.003       0.004       0.017\n",
       "key_1               -0.0101      0.002     -4.219      0.000      -0.015      -0.005\n",
       "key_6               -0.0105      0.003     -3.737      0.000      -0.016      -0.005\n",
       "key_8               -0.0086      0.003     -3.341      0.001      -0.014      -0.004\n",
       "time_signature       0.0018      0.001      1.572      0.116      -0.000       0.004\n",
       "key_3               -0.0046      0.003     -1.574      0.115      -0.010       0.001\n",
       "key_11              -0.0031      0.003     -1.172      0.241      -0.008       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      288.260   Durbin-Watson:                   1.944\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              290.941\n",
       "Skew:                          -0.130   Prob(JB):                     6.65e-64\n",
       "Kurtosis:                       3.048   Cond. No.                     2.16e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.16e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c048be7b072d6dd25b9ac428dc1fb9f8714e6b09effa99acd4035ec8dbeb08"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
